{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. How Surprise works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Specifying How to read the file through Reader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='item user rating timestamp', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 2, 3]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reader class will automatically re arranges the indices to form tuples ie.,\n",
    "# (user, item, rating, timestamp) irrespective of what our order is...\n",
    "reader.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load the dataset from file (sample.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  by using Reader object, which knows how the data is stored in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD the dataset.....\n",
    "data = Dataset.load_from_file('sample.csv',reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sample.csv',\n",
       " [('1013034', '14890', 5.0, '2005-07-07'),\n",
       "  ('413056', '17169', 5.0, '2005-06-14'),\n",
       "  ('823022', '9526', 3.0, '2003-04-01')],\n",
       " 100000)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset, literally means making tuples of our data..\n",
    "data.ratings_file, data.raw_ratings[:3], len(data.raw_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Preparing Dataset :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Creating the Trainset and Testset Object:\n",
    "- If you want to split the data into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Now let's make Training and Testing Set to train our algorithm....\n",
    "\n",
    "\n",
    "* It returns a Trainset object... and testset( list of tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Trainingset is a Trainset class object that store various information along with user item rating, which is useful for furthur computations **.\n",
    "\n",
    "\n",
    "* **Trainset** has some  ***defaultdict's of user and item***. A dictionary of UserIds(replaced with indeces of ordering) that contains list of (item, ratings) pairs. Even Item Id's are also \n",
    " replaced with indices (in the order of occurance,)\n",
    "\n",
    "\n",
    " * But the data is not corrupted by doing this. It preserves same User-Item\n",
    "as before. But now with new Indices...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise.trainset.Trainset"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [(0, 4.0)]),\n",
       " (1, [(1, 4.0), (2350, 3.0), (159, 3.0)]),\n",
       " (2, [(2, 5.0), (2659, 4.0), (73, 4.0)]),\n",
       " (3, [(3, 3.0)]),\n",
       " (4, [(4, 3.0), (1844, 3.0), (1246, 4.0)]),\n",
       " (5, [(5, 5.0)]),\n",
       " (6, [(6, 5.0)]),\n",
       " (7, [(7, 4.0), (673, 3.0)]),\n",
       " (8, [(8, 2.0), (3251, 4.0)]),\n",
       " (9, [(9, 3.0)])]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainset.ur.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you want to know abou any user, we can get them by indexing defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 3.0), (1844, 3.0), (1246, 4.0)]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.ur[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Here is how the Testset looks like* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, [('1974804', '7163', 3.0), ('286397', '2389', 3.0)])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (user, item, rating) pairs\n",
    "\n",
    "type(testset), testset[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Creating only Trainset:\n",
    "- If you want to train with all the data in input file\n",
    "\n",
    "- It is done only when you have saperate file for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_1 = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The training set structure is same as above ( some info along with default dicts of user and item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We can get that mappings of users and items to inner_item_ids and inner_user_ids***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_mapping: [('1427149', 0), ('997033', 1), ('1058842', 2)]\n",
      "Item_mapping: [('16242', 0), ('8904', 1), ('4306', 2)]\n"
     ]
    }
   ],
   "source": [
    "# 'OriginalItemIds' to 'NewItemIds' are stored in \"_raw2inner_items\" \n",
    "# Similarly, The mappings from 'OriginalUserIds' to 'NewUserIds' are like..\n",
    "\n",
    "print('User_mapping:',list(trainset._raw2inner_id_users.items())[:3])\n",
    "print('Item_mapping:',list(trainset._raw2inner_id_items.items())[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Some info that a Trainingset has ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.608373333333333, 8376, True)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It has several useful methods that are userful while training the model..\n",
    "# Example:\n",
    "trainset.global_mean, trainset.n_items, trainset.knows_item(3241)\n",
    "# and much more, where they are used inside the library while training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Run the SVD algorithm on the data (Trainingset Object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================\n",
    "### A sneak Peek in the algorithm\n",
    "\n",
    "- It is not purely SVD, it is **inspired from SVD**.\n",
    "\n",
    "\n",
    "- The standard SVD is modified for this Rating Prediction problem, by considering user biases, Item biases to make this new SVD. It uses **SGD** to solve optimization problem..(** With Regularization**)\n",
    "\n",
    "\n",
    "- In this we will solve the optimization problem of minimiZing the error by considering Biases of user and Item..\n",
    "\n",
    "http://www.albertauyeung.com/post/python-matrix-factorization/\n",
    "\n",
    "**Implementation is completely different in the above blogpost, But the concept is same**\n",
    "\n",
    "> ***Our Predicted Rating can be calculated from the following***\n",
    "\n",
    "\\begin{aligned}\n",
    "\\hat{r}_{ui} = \\mu + b_u + b_i + q_i^Tp_u\n",
    "\\end{aligned}\n",
    "\n",
    "=============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithm.....\n",
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lr_all : Learning rate for all hyperparameters.. (can make diffrnt lrngrates for diffrnt param)\n",
    "\n",
    "\n",
    "* reg_all: Regularization term for all parameters. (Can make diffrnt RegParams for diffrnt param)\n",
    "\n",
    "\n",
    "* with default parameters... (lr_all and reg_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We can make unbiased SVD also....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1c125ea7ba8>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(random_state=15, biased=True, verbose=True, lr_all=0.007, reg_all=0.02) \n",
    "algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **20 is the defalut no of epochs for SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1c125ea7ba8>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Train the model on the dataset (trainset)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Model Evaluation using RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 We can make it very easy if we have created testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.prediction_algorithms.predictions.Prediction'>\n",
      "----------------------------------------\n",
      "Prediction Instance\n",
      "----------------------------------------\n",
      "user: 1974804    item: 7163       r_ui = 3.00   est = 3.33   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "print(type(predictions[0]))\n",
    "print('-'*40)\n",
    "print('Prediction Instance')\n",
    "print('-'*40)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We can directly compute RMSE from predictions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0369002579766469"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating RMSE \n",
    "from surprise import accuracy\n",
    "accuracy.rmse(predictions, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 If we have Testdata in saperately( not in Testset format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***1.5.2.1 We can predict the rating directly from the library***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.608373333333333"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also ask for individual predictions of the User-Item prediction.\n",
    "algo.estimate(u=str(2422966), i=str(6439))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***1.5.2.2 Getting the ACTUAL RATING from the data with USERID and ITEMID***\n",
    "    - (to compute error ==> RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***ir*** is a DEFAULT DICT of items with lists having tuples of (user, rating)\n",
    "* item and user are in the form of inner_user_id and inner_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ratings = trainset.ir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets just say, we want the rating of (user, item) from our training set.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, i = '1013034', '14890' # actual ids from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert the **userid and itemid** into **innerIds in **trainingset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid = trainset.to_inner_iid(i) # Item_Inner_Id\n",
    "uid = trainset.to_inner_uid(u)  # User_Inner_Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We can get all the ***(user, rating)*** pairs who rated that (***movie ie., iid***)\n",
    " \n",
    " - We will convert that into dictionary for faster accesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_rating_dict = dict(item_ratings[iid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will predict it only if it is in our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.knows_item(iid) and trainset.knows_user(uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***We can Now get the rating of any user who rated that movie..***\n",
    "    * We don''t get any key error, because we are checking before acceing the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_rating_dict[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
